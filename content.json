{"meta":{"title":"Chao Ouyang's Blog","subtitle":null,"description":null,"author":"Chao Ouyang","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2018-04-11T13:32:27.000Z","updated":"2018-04-11T13:34:01.671Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"关于我Github: https://github.com/OuyangChao"},{"title":"categories","date":"2018-04-11T13:31:42.000Z","updated":"2018-04-11T13:31:55.206Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-04-11T13:31:00.000Z","updated":"2018-04-11T13:31:24.682Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"R-CNN","slug":"R-CNN","date":"2018-04-14T15:24:00.000Z","updated":"2018-04-14T15:28:50.221Z","comments":true,"path":"2018/04/14/R-CNN/","link":"","permalink":"http://yoursite.com/2018/04/14/R-CNN/","excerpt":"R-CNN，结合Region Proposal和CNN的目标检测算法。使用Region Proposal (Selective Search)算法得到有可能是目标的若干图像局部区域，然后把这些区域分别输入到CNN中，得到区域的特征，加上SVM分类器，判断特征对应的区域是属于某类目标还是背景，最后进行边框回归。","text":"R-CNN，结合Region Proposal和CNN的目标检测算法。使用Region Proposal (Selective Search)算法得到有可能是目标的若干图像局部区域，然后把这些区域分别输入到CNN中，得到区域的特征，加上SVM分类器，判断特征对应的区域是属于某类目标还是背景，最后进行边框回归。 Introduction在R-CNN之前，目标检测已经到了瓶颈期，一些最好的方法都是结合底层图像特征和高层语义的复杂集成系统。而这篇论文在VOC2012的mAP达到了53.3%，比之前最好的方法高30%。该方法主要有两个关键点：1）一个是将CNN应用在了自底向上的区域候选框上，用来定位和分割目标；2）当标记的训练数据比较少时，采用有监督预训练，并进行微调，可以显著提高性能。 R-CNNOverviewR-CNN的目标检测系统由三部分组成：第一步生成region proposal，采用selective search算法；第二步使用CNN提取固定长度的特征向量；第三步使用线性SVM分类。 Training 有监督预训练：在ILSVRC2012分类数据集上预训练。 微调：使用目标检测的数据进行微调，以0.001的学习速率进行SGD训练。对某个分类只要IoU&gt;0.5就视该边框为正值。每次SGD迭代都采样38个正边框和96个背景。 分类器：对某个分类，高IoU和低IoU都很好区分，但IoU处于中值时则很难定义生成的候选框是否包含了该物体。作者设定了一个阈值0.3（从一系列阈值中选择的，0,0.1,…,0.5），低于它的一律视为背景（负数）。另外，每个分类都优化一个SVM。由于负样本很多，因此还采用了hard negative mining方法。 Testing 采用selective search提取约2000个region proposal，将每个region proposal缩放成227*227，利用CNN前向运算计算特征。然后，使用训练好的SVM对特征进行分类，最后采用NMS去除多余的region。 运行时间分析：有两个因素使得检测效率较高，首先所有CNN参数对所有类别都是共享的，其次，由CNN计算出来的特征向量相比其他方法是低维特征。 一些问题 可以不进行特定样本下的微调吗？可以直接采用AlexNet网络的特征进行SVM训练吗? ⽂中设计了没有进⾏微调的对⽐实验，分别就AlexNet⽹络的pool5、fc6、fc7层进⾏特征提取，输⼊SVM进⾏训练，这相当于把AlexNet网络作为特征提取器，类似HOG、SIFT等做特征提取⼀样，不针对特征任务。实验结果发现f6层提取的特征⽐f7层的mAP还⾼，pool5层提取的特征与f6、f7层相⽐mAP差不多； 在PASCAL VOC 2007数据集上采取了微调后fc6、fc7层特征较pool5层特征⽤于SVM训练提升mAP⼗分明显； 由此作者得出结论：不针对特定任务进⾏微调，⽽将CNN当成特征提取器，pool5层得到的特征是基础特征，类似于HOG、SIFT，类似于只学习到了⼈脸共性特征；从fc6和fc7等全连接层中所学习到的特征是针对特征任务特定样本的特征，类似于学习到了分类性别分类年龄的个性特征。 为什么微调时和训练SVM时所采⽤的正负样本阈值【0.5和0.3】不⼀致？ 微调阶段是由于CNN对⼩样本容易过拟合，需要⼤量训练数据，故对IoU限制宽松：与Ground Truth相交IoU&gt;0.5的建议框为正样本，否则为负样本； SVM这种机制是由于其适⽤于⼩样本训练，故对样本IoU限制严格：Ground Truth为正样本，与Ground Truth相交IoU＜0.3的建议框为负样本。 为什么不直接采⽤微调后的AlexNet⽹络最后⼀层SoftMax进⾏21分类【20类+背景】？ 因为微调时和训练SVM时所采⽤的正负样本阈值不同，微调阶段正样本定义并不强调精准的位置，⽽SVM正样本只有Ground Truth；并且微调阶段的负样本是随机抽样的，⽽SVM的负样本是经过hard negative mining⽅法筛选的；导致在采⽤SoftMax会使PSACAL VOC 2007测试集上mAP从54.2%降低到50.9%。 R-CNN速度慢在哪里？ RCNN存在着重复计算的问题（proposal的region有几千个，多数都是互相重叠，重叠部分会被多次重复提取feature）。 Reference Rich feature hierarchies for accurate object detection and semantic segmentation Caffe源码实现 R-CNN论文详解","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://yoursite.com/categories/论文笔记/"}],"tags":[{"name":"Deep learning","slug":"Deep-learning","permalink":"http://yoursite.com/tags/Deep-learning/"},{"name":"CNN","slug":"CNN","permalink":"http://yoursite.com/tags/CNN/"}]},{"title":"Spatial Transformer Networks","slug":"Spatial-Transformer-Networks","date":"2018-04-12T04:51:11.000Z","updated":"2018-04-13T08:31:32.682Z","comments":true,"path":"2018/04/12/Spatial-Transformer-Networks/","link":"","permalink":"http://yoursite.com/2018/04/12/Spatial-Transformer-Networks/","excerpt":"传统CNN通过扩增数据获得数据的一些不变性，如旋转不变性，平移不变性等，是一种隐式的学习，而空间变换网络（Spatial Transformer Networks，简称STN）通过显式学习数据的各种变换参数（如旋转，平移，仿射变换等）来获得这些变换的不变性。这个网络可以很方便的插入到已有的CNN网络中。","text":"传统CNN通过扩增数据获得数据的一些不变性，如旋转不变性，平移不变性等，是一种隐式的学习，而空间变换网络（Spatial Transformer Networks，简称STN）通过显式学习数据的各种变换参数（如旋转，平移，仿射变换等）来获得这些变换的不变性。这个网络可以很方便的插入到已有的CNN网络中。 Introduction 不变性（invariance）：在CNN中，pooling层使得网络对位置的敏感度越来越低，从而使网络具有一定的平移不变性。这种空间不变性是通过多层的conv和pooling层实现的，而且对变换较大的输入数据并不具有不变性。 Spatial Transformer: 引入空间变换模块（spatial transformer module），可以添加到任何一个标准的神经网络结构中，从而提供空间变换的能力。与pooling层不同，空间变换模块是一个动态的机制，训练得到合适的变换参数，然后将这个变换应用在整个feature map上，可以覆盖scaling, cropping, ratations等变换。这样的好处是可以使得网络选择出一幅图像中最相关的区域，如下图所示，(a)是输入图像，(b)是空间变换模块预测的定位结果，(c)是空间变换后的结果，(d)是分类结果。 应用：STN可以嵌入CNN中实现不同的任务，例如： image classification: STN可以crop out和scale-normalize合适的区域，简化接下来的分类任务，提高分类性能； co-localisation: 不需要标记目标的位置，通过STN，可以定位目标； spatial attention: 可以实现attention机制，很灵活，无需增强学习。 Spatial Transformers由以下三部分组成 Localisation Network: 输入feature map，输出$\\theta$。$\\theta$的尺寸取决于变换类型，比如对于仿射变换，$\\theta$就是6维的。这个网络可以采用任意形式，比如全连接网络或卷积网络，但是最后应该有一个回归层输出参数$\\theta$。 Parameterised Sampling Grid: 以下是将Parameterised Sampling Grid应用到图像U上得到输出V的两个例子，图(a)是一个单位变换，图(b)是一个仿射变换。 Differentiable Image Sampling: 这一步是将输入的feature map结合变换参数，输出结果feature map。 个人总结传统CNN通过各种数据扩增操作来获得某些不变性（如平移不变性，旋转不变性等），是一种“隐式学习”的方法，即我们只是向网络输入数据，直接输出的就是预测结果。而STN主要是一种“显式学习”空间变换参数的方法，它通过训练得到这些参数，对输入数据（也可以是中间的feature map）进行变换，使得后续的处理能得到更好的结果。 优点：容易扩展，可以很方便的嵌入其它网络中；与CNN是直接识别出扭曲图像不同，STN显然更符合人类识别的过程，即先将图像纠正再识别。 缺点：训练时依然需要大量数据扩增才能学到所需要的不变性，而且学习到的变换参数不一定是我们希望的。 复现过程：对Mnist数据集进行随机旋转，然后使用论文中提到的超参数设置，结果显示采用STN后在测试集上的准确率确实高于不使用STN的时候。但是对STN层后的输出进行可视化后并没有原文中效果那么好，比如我需要学习的是旋转不变性，但是结果显示STN层所做的事情是平移而不是旋转。我认为可能在学习旋转不变性时需要固定6个变换参数中的某几个，使得能够显式的学习旋转不变性。 Reference Spatial Transformer Networks (NIPS, 2015) 李宏毅-深度学习-Spatial Transformer Layer Paper Reading：Spatial Transformer Networks（with code explanation） Caffe实现版本 Tensorflow实现版本 PyTorch实现版本 MXNet实现版本","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://yoursite.com/categories/论文笔记/"}],"tags":[{"name":"Deep learning","slug":"Deep-learning","permalink":"http://yoursite.com/tags/Deep-learning/"},{"name":"CNN","slug":"CNN","permalink":"http://yoursite.com/tags/CNN/"}]}]}